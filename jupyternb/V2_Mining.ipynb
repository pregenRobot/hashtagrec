{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T21:38:41.471440Z",
     "start_time": "2020-06-10T21:38:41.464920Z"
    }
   },
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot\n",
    "# jtplot.style(theme=\"gruvboxd\")\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T13:33:19.378636Z",
     "start_time": "2020-06-10T13:33:19.363086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      23424748\n",
       "1       1099805\n",
       "2       1100661\n",
       "3       1100968\n",
       "4       1101597\n",
       "         ...   \n",
       "105     2503713\n",
       "106     2503863\n",
       "107     2508428\n",
       "108     2512636\n",
       "109     2514815\n",
       "Name: woeid, Length: 110, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_trends = pd.read_csv(\"mined_data/available_trends.csv\")\n",
    "available_woeid = available_trends.iloc[:,5]\n",
    "available_woeid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T21:39:18.428269Z",
     "start_time": "2020-06-10T21:39:18.422044Z"
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "consumer_key = \"WwEbwqeW01Yy6WLj7OEQekl8W\"\n",
    "consumer_secret = \"phmcmDEfZyVz44f3MeVO9eLkbFsh6TPFe7qTWpfBTGYNJCZs9D\"\n",
    "access_token = \"1001251273981677568-iarpqVNKAQ28iDzcyU0QS7H50FCokR\"\n",
    "access_token_secret = \"BJoB0WH59h2vWejzyxDmunPQZFbEk0uN0dfoYFH1WGcf5\"\n",
    "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:23:56.675344Z",
     "start_time": "2020-06-10T08:23:56.670530Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_woeid_details(woeid):\n",
    "    locations = api.trends_available()\n",
    "    \n",
    "    for i in range(len(locations)):\n",
    "        if(locations[i][\"woeid\"] == woeid):\n",
    "            return locations[i][\"name\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:48:47.059879Z",
     "start_time": "2020-06-10T08:24:04.757898Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_of_hashtags = []\n",
    "for i in range(len(available_woeid)):\n",
    "    woeid = available_woeid[i]\n",
    "    trends = api.trends_place(woeid)[0][\"trends\"]\n",
    "    for ii in range(len(trends)):\n",
    "        trend = trends[ii][\"name\"]\n",
    "        if(trend[:1]==\"#\"):\n",
    "            list_of_hashtags.append(trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T08:48:47.150577Z",
     "start_time": "2020-06-10T08:48:47.140427Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "list_of_hashtags = list(set(list_of_hashtags))\n",
    "\n",
    "with open('mined_data/hashtags_200610.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for val in list_of_hashtags: \n",
    "        writer.writerow([val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T21:38:46.205755Z",
     "start_time": "2020-06-10T21:38:46.188135Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           #1ofTheMillion\n",
       "1                    #INwx\n",
       "2                    #newx\n",
       "3      #ChampionshipLeague\n",
       "4                  #hokies\n",
       "              ...         \n",
       "137                  #twug\n",
       "138                #Pompey\n",
       "139                #TikTok\n",
       "140                  #UTSA\n",
       "141       #shortlandstreet\n",
       "Name: #VoterSuppressionInGeoriga, Length: 142, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_hashtags = pd.read_csv(\"mined_data/hashtags_200610.csv\")\n",
    "available_hashtags.head()\n",
    "\n",
    "available_hashtags.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T10:13:31.465541Z",
     "start_time": "2020-06-10T21:43:23.739420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "Retrieved 986 tweets about #1ofTheMillion\n",
      "Check if y length matches: 986\n",
      "Current num of newhashtags: 1277\n",
      "Current documents: 986\n",
      "Retrieved 991 tweets about #INwx\n",
      "Check if y length matches: 991\n",
      "Current num of newhashtags: 2672\n",
      "Current documents: 1977\n",
      "Retrieved 960 tweets about #newx\n",
      "Check if y length matches: 960\n",
      "Current num of newhashtags: 4108\n",
      "Current documents: 2937\n",
      "Retrieved 946 tweets about #ChampionshipLeague\n",
      "Check if y length matches: 946\n",
      "Current num of newhashtags: 5211\n",
      "Current documents: 3883\n",
      "Retrieved 965 tweets about #hokies\n",
      "Check if y length matches: 965\n",
      "Current num of newhashtags: 6431\n",
      "Current documents: 4848\n",
      "Retrieved 875 tweets about #gotiges\n",
      "Check if y length matches: 875\n",
      "Current num of newhashtags: 7314\n",
      "Current documents: 5723\n",
      "Retrieved 669 tweets about #TWUG\n",
      "Check if y length matches: 669\n",
      "Current num of newhashtags: 8257\n",
      "Current documents: 6392\n",
      "Retrieved 987 tweets about #filthyrichhomeless\n",
      "Check if y length matches: 987\n",
      "Current num of newhashtags: 9164\n",
      "Current documents: 7379\n",
      "Retrieved 967 tweets about #RikMayall\n",
      "Check if y length matches: 967\n",
      "Current num of newhashtags: 9629\n",
      "Current documents: 8346\n",
      "Retrieved 932 tweets about #BBAU\n",
      "Check if y length matches: 932\n",
      "Current num of newhashtags: 10760\n",
      "Current documents: 9278\n",
      "Retrieved 932 tweets about #ShutDownSTEM\n",
      "Check if y length matches: 932\n",
      "Current num of newhashtags: 11943\n",
      "Current documents: 10210\n",
      "Retrieved 928 tweets about #TuckerCarlsonIsARacist\n",
      "Check if y length matches: 928\n",
      "Current num of newhashtags: 13011\n",
      "Current documents: 11138\n",
      "Retrieved 430 tweets about #CoronaVirus\n",
      "Check if y length matches: 430\n",
      "Current num of newhashtags: 13979\n",
      "Current documents: 11568\n",
      "Retrieved 994 tweets about #JavierAmbler\n",
      "Check if y length matches: 994\n",
      "Current num of newhashtags: 15081\n",
      "Current documents: 12562\n",
      "Retrieved 949 tweets about #BillandTedDay\n",
      "Check if y length matches: 949\n",
      "Current num of newhashtags: 15824\n",
      "Current documents: 13511\n",
      "Retrieved 850 tweets about #TuesdayThoughts\n",
      "Check if y length matches: 850\n",
      "Current num of newhashtags: 17457\n",
      "Current documents: 14361\n",
      "Retrieved 314 tweets about #aclib20\n",
      "Check if y length matches: 314\n",
      "Current num of newhashtags: 17792\n",
      "Current documents: 14675\n",
      "Retrieved 992 tweets about #agchatoz\n",
      "Check if y length matches: 992\n",
      "Current num of newhashtags: 18840\n",
      "Current documents: 15667\n",
      "Retrieved 941 tweets about #DefundThePolice\n",
      "Check if y length matches: 941\n",
      "Current num of newhashtags: 19691\n",
      "Current documents: 16608\n",
      "Retrieved 425 tweets about #coronavirus\n",
      "Check if y length matches: 425\n",
      "Current num of newhashtags: 20607\n",
      "Current documents: 17033\n",
      "Retrieved 979 tweets about #rufc\n",
      "Check if y length matches: 979\n",
      "Current num of newhashtags: 22018\n",
      "Current documents: 18012\n",
      "Retrieved 932 tweets about #WednesdayThoughts\n",
      "Check if y length matches: 932\n",
      "Current num of newhashtags: 24732\n",
      "Current documents: 18944\n",
      "Retrieved 629 tweets about #firekmarko\n",
      "Check if y length matches: 629\n",
      "Current num of newhashtags: 25374\n",
      "Current documents: 19573\n",
      "Retrieved 433 tweets about #AskIZONE\n",
      "Check if y length matches: 433\n",
      "Current num of newhashtags: 25994\n",
      "Current documents: 20006\n",
      "Retrieved 947 tweets about #WhatIRememberFrom2019\n",
      "Check if y length matches: 947\n",
      "Current num of newhashtags: 27377\n",
      "Current documents: 20953\n",
      "Retrieved 766 tweets about #nationalnotfittogovern\n",
      "Check if y length matches: 766\n",
      "Current num of newhashtags: 28845\n",
      "Current documents: 21719\n",
      "Retrieved 836 tweets about #PrincePhilip\n",
      "Check if y length matches: 836\n",
      "Current num of newhashtags: 30341\n",
      "Current documents: 22555\n",
      "Retrieved 898 tweets about #BookerBeatsMitch\n",
      "Check if y length matches: 898\n",
      "Current num of newhashtags: 31180\n",
      "Current documents: 23453\n",
      "Retrieved 970 tweets about #90DayFiance\n",
      "Check if y length matches: 970\n",
      "Current num of newhashtags: 32560\n",
      "Current documents: 24423\n",
      "Retrieved 998 tweets about #ctrlturns3\n",
      "Check if y length matches: 998\n",
      "Current num of newhashtags: 32581\n",
      "Current documents: 25421\n",
      "Retrieved 946 tweets about #Classof2020\n",
      "Check if y length matches: 946\n",
      "Current num of newhashtags: 34130\n",
      "Current documents: 26367\n",
      "Retrieved 986 tweets about #OnlyVegas\n",
      "Check if y length matches: 986\n",
      "Current num of newhashtags: 35110\n",
      "Current documents: 27353\n",
      "Retrieved 988 tweets about #festivalofwork\n",
      "Check if y length matches: 988\n",
      "Current num of newhashtags: 36585\n",
      "Current documents: 28341\n",
      "Retrieved 721 tweets about #NVPrimary\n",
      "Check if y length matches: 721\n",
      "Current num of newhashtags: 37436\n",
      "Current documents: 29062\n",
      "Retrieved 952 tweets about #NevadaPrimary\n",
      "Check if y length matches: 952\n",
      "Current num of newhashtags: 38752\n",
      "Current documents: 30014\n",
      "Retrieved 928 tweets about #RhodesMustFall\n",
      "Check if y length matches: 928\n",
      "Current num of newhashtags: 39778\n",
      "Current documents: 30942\n",
      "Retrieved 978 tweets about #pumprules\n",
      "Check if y length matches: 978\n",
      "Current num of newhashtags: 41059\n",
      "Current documents: 31920\n",
      "Retrieved 131 tweets about #VisionweekNZ\n",
      "Check if y length matches: 131\n",
      "Current num of newhashtags: 41227\n",
      "Current documents: 32051\n",
      "Retrieved 901 tweets about #pdxtraffic\n",
      "Check if y length matches: 901\n",
      "Current num of newhashtags: 42352\n",
      "Current documents: 32952\n",
      "Retrieved 926 tweets about #PUSB\n",
      "Check if y length matches: 926\n",
      "Current num of newhashtags: 42970\n",
      "Current documents: 33878\n",
      "Retrieved 330 tweets about #Kcwx\n",
      "Check if y length matches: 330\n",
      "Current num of newhashtags: 43747\n",
      "Current documents: 34208\n",
      "Retrieved 912 tweets about #VoteByMail\n",
      "Check if y length matches: 912\n",
      "Current num of newhashtags: 45897\n",
      "Current documents: 35120\n",
      "Retrieved 944 tweets about #CookForASongOrMovie\n",
      "Check if y length matches: 944\n",
      "Current num of newhashtags: 46835\n",
      "Current documents: 36064\n",
      "Retrieved 987 tweets about #SeattleAutonomousZone\n",
      "Check if y length matches: 987\n",
      "Current num of newhashtags: 47842\n",
      "Current documents: 37051\n",
      "Retrieved 780 tweets about #wednesdaymorning\n",
      "Check if y length matches: 780\n",
      "Current num of newhashtags: 49422\n",
      "Current documents: 37831\n",
      "Retrieved 935 tweets about #WMTY20\n",
      "Check if y length matches: 935\n",
      "Current num of newhashtags: 50438\n",
      "Current documents: 38766\n",
      "Retrieved 216 tweets about #ukpolitics\n",
      "Check if y length matches: 216\n",
      "Current num of newhashtags: 51149\n",
      "Current documents: 38982\n",
      "Retrieved 968 tweets about #iflovingyouiswrong\n",
      "Check if y length matches: 968\n",
      "Current num of newhashtags: 52460\n",
      "Current documents: 39950\n",
      "Retrieved 965 tweets about #CarersWeek2020\n",
      "Check if y length matches: 965\n",
      "Current num of newhashtags: 53723\n",
      "Current documents: 40915\n",
      "Retrieved 490 tweets about #sunshinejunday\n",
      "Check if y length matches: 490\n",
      "Current num of newhashtags: 54457\n",
      "Current documents: 41405\n",
      "Retrieved 914 tweets about #ShutDownAcademia\n",
      "Check if y length matches: 914\n",
      "Current num of newhashtags: 55778\n",
      "Current documents: 42319\n",
      "Retrieved 936 tweets about #solidaritea\n",
      "Check if y length matches: 936\n",
      "Current num of newhashtags: 56481\n",
      "Current documents: 43255\n",
      "Retrieved 995 tweets about #gapol\n",
      "Check if y length matches: 995\n",
      "Current num of newhashtags: 57542\n",
      "Current documents: 44250\n",
      "Retrieved 907 tweets about #TrumpMeltdown\n",
      "Check if y length matches: 907\n",
      "Current num of newhashtags: 59483\n",
      "Current documents: 45157\n",
      "Retrieved 965 tweets about #shutdownstem\n",
      "Check if y length matches: 965\n",
      "Current num of newhashtags: 60427\n",
      "Current documents: 46122\n",
      "Retrieved 494 tweets about #Bluebirds\n",
      "Check if y length matches: 494\n",
      "Current num of newhashtags: 61935\n",
      "Current documents: 46616\n",
      "Retrieved 995 tweets about #MyHeroOnesJustice2\n",
      "Check if y length matches: 995\n",
      "Current num of newhashtags: 63391\n",
      "Current documents: 47611\n",
      "Retrieved 996 tweets about #SittingInLimbo\n",
      "Check if y length matches: 996\n",
      "Current num of newhashtags: 64193\n",
      "Current documents: 48607\n",
      "Retrieved 885 tweets about #GeorgeFloyd\n",
      "Check if y length matches: 885\n",
      "Current num of newhashtags: 65367\n",
      "Current documents: 49492\n",
      "Retrieved 725 tweets about #VogueChallenge\n",
      "Check if y length matches: 725\n",
      "Current num of newhashtags: 66177\n",
      "Current documents: 50217\n",
      "Retrieved 831 tweets about #WednesdayWisdom\n",
      "Check if y length matches: 831\n",
      "Current num of newhashtags: 67551\n",
      "Current documents: 51048\n",
      "Retrieved 820 tweets about #VoteBlueToSaveAmerica\n",
      "Check if y length matches: 820\n",
      "Current num of newhashtags: 68972\n",
      "Current documents: 51868\n",
      "Retrieved 954 tweets about #amwriting\n",
      "Check if y length matches: 954\n",
      "Current num of newhashtags: 71717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current documents: 52822\n",
      "Retrieved 937 tweets about #GeorgeFloydFuneral\n",
      "Check if y length matches: 937\n",
      "Current num of newhashtags: 73474\n",
      "Current documents: 53759\n",
      "Retrieved 766 tweets about #tuesdaythoughts\n",
      "Check if y length matches: 766\n",
      "Current num of newhashtags: 74888\n",
      "Current documents: 54525\n",
      "Retrieved 23 tweets about #apaxx\n",
      "Check if y length matches: 23\n",
      "Current num of newhashtags: 75004\n",
      "Current documents: 54548\n",
      "Retrieved 997 tweets about #CerealsLIVE2020\n",
      "Check if y length matches: 997\n",
      "Current num of newhashtags: 76226\n",
      "Current documents: 55545\n",
      "Retrieved 804 tweets about #GoPies\n",
      "Check if y length matches: 804\n",
      "Current num of newhashtags: 77107\n",
      "Current documents: 56349\n",
      "Retrieved 976 tweets about #bloggerstribe\n",
      "Check if y length matches: 976\n",
      "Current num of newhashtags: 79538\n",
      "Current documents: 57325\n",
      "Retrieved 879 tweets about #adoptmetrades\n",
      "Check if y length matches: 879\n",
      "Current num of newhashtags: 82194\n",
      "Current documents: 58204\n",
      "Retrieved 975 tweets about #90dayfiance\n",
      "Check if y length matches: 975\n",
      "Current num of newhashtags: 83588\n",
      "Current documents: 59179\n",
      "Retrieved 938 tweets about #defundthepolice\n",
      "Check if y length matches: 938\n",
      "Current num of newhashtags: 84415\n",
      "Current documents: 60117\n",
      "Retrieved 986 tweets about #BoycottSainsburys\n",
      "Check if y length matches: 986\n",
      "Current num of newhashtags: 85150\n",
      "Current documents: 61103\n",
      "Retrieved 407 tweets about #LoveWhereYouWork\n",
      "Check if y length matches: 407\n",
      "Current num of newhashtags: 86138\n",
      "Current documents: 61510\n",
      "Retrieved 988 tweets about #EmpathyDay\n",
      "Check if y length matches: 988\n",
      "Current num of newhashtags: 87284\n",
      "Current documents: 62498\n",
      "Retrieved 767 tweets about #golobos\n",
      "Check if y length matches: 767\n",
      "Current num of newhashtags: 88087\n",
      "Current documents: 63265\n",
      "Retrieved 605 tweets about #FutureGeo\n",
      "Check if y length matches: 605\n",
      "Current num of newhashtags: 88726\n",
      "Current documents: 63870\n",
      "Retrieved 916 tweets about #CCFC\n",
      "Check if y length matches: 916\n",
      "Current num of newhashtags: 89979\n",
      "Current documents: 64786\n",
      "Retrieved 878 tweets about #GAVoterSuppression\n",
      "Check if y length matches: 878\n",
      "Current num of newhashtags: 91131\n",
      "Current documents: 65664\n",
      "Retrieved 835 tweets about #melnykout\n",
      "Check if y length matches: 835\n",
      "Current num of newhashtags: 91990\n",
      "Current documents: 66499\n",
      "Retrieved 921 tweets about #UFC251\n",
      "Check if y length matches: 921\n",
      "Current num of newhashtags: 94395\n",
      "Current documents: 67420\n",
      "Retrieved 439 tweets about #getconnectedvirtual\n",
      "Check if y length matches: 439\n",
      "Current num of newhashtags: 95028\n",
      "Current documents: 67859\n",
      "Retrieved 708 tweets about #PlayStation5\n",
      "Check if y length matches: 708\n",
      "Current num of newhashtags: 96224\n",
      "Current documents: 68567\n",
      "Retrieved 992 tweets about #CarersWeek\n",
      "Check if y length matches: 992\n",
      "Current num of newhashtags: 97144\n",
      "Current documents: 69559\n",
      "Retrieved 924 tweets about #dylanwasframed\n",
      "Check if y length matches: 924\n",
      "Current num of newhashtags: 99295\n",
      "Current documents: 70483\n",
      "Retrieved 512 tweets about #AlienGossip\n",
      "Check if y length matches: 512\n",
      "Current num of newhashtags: 99819\n",
      "Current documents: 70995\n",
      "Retrieved 958 tweets about #GoBucks\n",
      "Check if y length matches: 958\n",
      "Current num of newhashtags: 101244\n",
      "Current documents: 71953\n",
      "Retrieved 989 tweets about #lagov\n",
      "Check if y length matches: 989\n",
      "Current num of newhashtags: 101804\n",
      "Current documents: 72942\n",
      "Retrieved 146 tweets about #G5QS\n",
      "Check if y length matches: 146\n",
      "Current num of newhashtags: 101951\n",
      "Current documents: 73088\n",
      "Retrieved 526 tweets about #Lorraine\n",
      "Check if y length matches: 526\n",
      "Current num of newhashtags: 102955\n",
      "Current documents: 73614\n",
      "Retrieved 911 tweets about #BillAndTed3\n",
      "Check if y length matches: 911\n",
      "Current num of newhashtags: 104095\n",
      "Current documents: 74525\n",
      "Retrieved 505 tweets about #COVID__19\n",
      "Check if y length matches: 505\n",
      "Current num of newhashtags: 104966\n",
      "Current documents: 75030\n",
      "Retrieved 954 tweets about #triviatuesday\n",
      "Check if y length matches: 954\n",
      "Current num of newhashtags: 106557\n",
      "Current documents: 75984\n",
      "Retrieved 980 tweets about #PumpRules\n",
      "Check if y length matches: 980\n",
      "Current num of newhashtags: 108026\n",
      "Current documents: 76964\n",
      "Retrieved 992 tweets about #mowx\n",
      "Check if y length matches: 992\n",
      "Current num of newhashtags: 109717\n",
      "Current documents: 77956\n",
      "Retrieved 770 tweets about #twitch\n",
      "Check if y length matches: 770\n",
      "Current num of newhashtags: 112858\n",
      "Current documents: 78726\n",
      "Retrieved 965 tweets about #BighornFire\n",
      "Check if y length matches: 965\n",
      "Current num of newhashtags: 114341\n",
      "Current documents: 79691\n",
      "Retrieved 104 tweets about #IndyTV2020\n",
      "Check if y length matches: 104\n",
      "Current num of newhashtags: 114422\n",
      "Current documents: 79795\n",
      "Retrieved 973 tweets about #CHAZ\n",
      "Check if y length matches: 973\n",
      "Current num of newhashtags: 115528\n",
      "Current documents: 80768\n",
      "Retrieved 861 tweets about #Trump2020\n",
      "Check if y length matches: 861\n",
      "Current num of newhashtags: 117375\n",
      "Current documents: 81629\n",
      "Retrieved 954 tweets about #DougDuceyHologram\n",
      "Check if y length matches: 954\n",
      "Current num of newhashtags: 118311\n",
      "Current documents: 82583\n",
      "Retrieved 997 tweets about #BigGive\n",
      "Check if y length matches: 997\n",
      "Current num of newhashtags: 119660\n",
      "Current documents: 83580\n",
      "Retrieved 642 tweets about #VoterSuppressionGA\n",
      "Check if y length matches: 642\n",
      "Current num of newhashtags: 120723\n",
      "Current documents: 84222\n",
      "Retrieved 992 tweets about #cosen\n",
      "Check if y length matches: 992\n",
      "Current num of newhashtags: 122139\n",
      "Current documents: 85214\n",
      "Retrieved 275 tweets about #365dni\n",
      "Check if y length matches: 275\n",
      "Current num of newhashtags: 122443\n",
      "Current documents: 85489\n",
      "Retrieved 567 tweets about #COVID19\n",
      "Check if y length matches: 567\n",
      "Current num of newhashtags: 123387\n",
      "Current documents: 86056\n",
      "Retrieved 927 tweets about #MSYKM\n",
      "Check if y length matches: 927\n",
      "Current num of newhashtags: 124232\n",
      "Current documents: 86983\n",
      "Retrieved 924 tweets about #alwaysproud\n",
      "Check if y length matches: 924\n",
      "Current num of newhashtags: 125071\n",
      "Current documents: 87907\n",
      "Retrieved 380 tweets about #ccicforum2020\n",
      "Check if y length matches: 380\n",
      "Current num of newhashtags: 125518\n",
      "Current documents: 88287\n",
      "Retrieved 976 tweets about #RacisminAustralia\n",
      "Check if y length matches: 976\n",
      "Current num of newhashtags: 125902\n",
      "Current documents: 89263\n",
      "Retrieved 955 tweets about #nrlbulldogsdragons\n",
      "Check if y length matches: 955\n",
      "Current num of newhashtags: 127229\n",
      "Current documents: 90218\n",
      "Retrieved 918 tweets about #ChristopherColumbus\n",
      "Check if y length matches: 918\n",
      "Current num of newhashtags: 129299\n",
      "Current documents: 91136\n",
      "Retrieved 921 tweets about #MAGA\n",
      "Check if y length matches: 921\n",
      "Current num of newhashtags: 130868\n",
      "Current documents: 92057\n",
      "Retrieved 441 tweets about #nyxed2020\n",
      "Check if y length matches: 441\n",
      "Current num of newhashtags: 131539\n",
      "Current documents: 92498\n",
      "Retrieved 813 tweets about #WorldOceansDay\n",
      "Check if y length matches: 813\n",
      "Current num of newhashtags: 132512\n",
      "Current documents: 93311\n",
      "Retrieved 999 tweets about #CTRLturns3\n",
      "Check if y length matches: 999\n",
      "Current num of newhashtags: 132529\n",
      "Current documents: 94310\n",
      "Retrieved 978 tweets about #homelessness\n",
      "Check if y length matches: 978\n",
      "Current num of newhashtags: 134648\n",
      "Current documents: 95288\n",
      "Retrieved 967 tweets about #tnleg\n",
      "Check if y length matches: 967\n",
      "Current num of newhashtags: 135009\n",
      "Current documents: 96255\n",
      "Retrieved 946 tweets about #FoxNews\n",
      "Check if y length matches: 946\n",
      "Current num of newhashtags: 136566\n",
      "Current documents: 97201\n",
      "Retrieved 960 tweets about #royalehightrades\n",
      "Check if y length matches: 960\n",
      "Current num of newhashtags: 139759\n",
      "Current documents: 98161\n",
      "Retrieved 987 tweets about #teacherfriends\n",
      "Check if y length matches: 987\n",
      "Current num of newhashtags: 140991\n",
      "Current documents: 99148\n",
      "Retrieved 245 tweets about #acnh\n",
      "Check if y length matches: 245\n",
      "Current num of newhashtags: 141459\n",
      "Current documents: 99393\n",
      "Retrieved 879 tweets about #GeorgeFloydMemorial\n",
      "Check if y length matches: 879\n",
      "Current num of newhashtags: 143886\n",
      "Current documents: 100272\n",
      "Retrieved 449 tweets about #WeFlyAsOne\n",
      "Check if y length matches: 449\n",
      "Current num of newhashtags: 144479\n",
      "Current documents: 100721\n",
      "Retrieved 989 tweets about #SB217\n",
      "Check if y length matches: 989\n",
      "Current num of newhashtags: 145387\n",
      "Current documents: 101710\n",
      "Retrieved 948 tweets about #BlackLivesMatterUK\n",
      "Check if y length matches: 948\n",
      "Current num of newhashtags: 146464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current documents: 102658\n",
      "Retrieved 8 tweets about #PL61\n",
      "Check if y length matches: 8\n",
      "Current num of newhashtags: 146475\n",
      "Current documents: 102666\n",
      "Retrieved 810 tweets about #tuesdayvibes\n",
      "Check if y length matches: 810\n",
      "Current num of newhashtags: 148330\n",
      "Current documents: 103476\n",
      "Retrieved 997 tweets about #robodebt\n",
      "Check if y length matches: 997\n",
      "Current num of newhashtags: 149388\n",
      "Current documents: 104473\n",
      "Retrieved 105 tweets about #mshwys\n",
      "Check if y length matches: 105\n",
      "Current num of newhashtags: 149445\n",
      "Current documents: 104578\n",
      "Retrieved 964 tweets about #PowerOfTogether\n",
      "Check if y length matches: 964\n",
      "Current num of newhashtags: 150090\n",
      "Current documents: 105542\n",
      "Retrieved 960 tweets about #MasterChefAU\n",
      "Check if y length matches: 960\n",
      "Current num of newhashtags: 151247\n",
      "Current documents: 106502\n",
      "Retrieved 930 tweets about #RacismIsAPublicHealthCrisis\n",
      "Check if y length matches: 930\n",
      "Current num of newhashtags: 152552\n",
      "Current documents: 107432\n",
      "Retrieved 585 tweets about #CIPD\n",
      "Check if y length matches: 585\n",
      "Current num of newhashtags: 154155\n",
      "Current documents: 108017\n",
      "Retrieved 652 tweets about #BlackLivesMattters\n",
      "Check if y length matches: 652\n",
      "Current num of newhashtags: 155122\n",
      "Current documents: 108669\n",
      "Retrieved 575 tweets about #GoneWithTheWind\n",
      "Check if y length matches: 575\n",
      "Current num of newhashtags: 156130\n",
      "Current documents: 109244\n",
      "Retrieved 986 tweets about #VoterSuppression\n",
      "Check if y length matches: 986\n",
      "Current num of newhashtags: 157078\n",
      "Current documents: 110230\n",
      "Retrieved 674 tweets about #twug\n",
      "Check if y length matches: 674\n",
      "Current num of newhashtags: 158056\n",
      "Current documents: 110904\n",
      "Retrieved 885 tweets about #Pompey\n",
      "Check if y length matches: 885\n",
      "Current num of newhashtags: 159254\n",
      "Current documents: 111789\n",
      "Retrieved 263 tweets about #TikTok\n",
      "Check if y length matches: 263\n",
      "Current num of newhashtags: 159970\n",
      "Current documents: 112052\n",
      "Retrieved 1000 tweets about #UTSA\n",
      "Check if y length matches: 1000\n",
      "Current num of newhashtags: 160970\n",
      "Current documents: 113052\n",
      "Retrieved 338 tweets about #shortlandstreet\n",
      "Check if y length matches: 338\n",
      "Current num of newhashtags: 161344\n",
      "Current documents: 113390\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "newhashtags = []\n",
    "X_document = []\n",
    "y_document = []\n",
    "\n",
    "print(len(available_hashtags))\n",
    "\n",
    "charsequence = [\".\",\"#\",\":\",\"•\",\",\",\"@\",\"\\\"\",\";\",\"\\'\",\")\",\"(\",\"&\",\"``\",\"\\'\\'\"]\n",
    "pipe = Pipeline(\n",
    "        [(\"tokenizetweet\",Tokenizer(tweettokenizer)),\n",
    "         (\"rmemoji\",ConvertEmojis(tweettokenizer)),\n",
    "         (\"rmpunctuation\",RemovePunctuation(charsequence)),\n",
    "         (\"standardizetweets\",Standardize())]\n",
    ")\n",
    "\n",
    "for i in range(len(available_hashtags.iloc[:,0])):\n",
    "    hashtag = available_hashtags.iloc[i,0]\n",
    "    \n",
    "    extractor = HashtagDetailsExtractor()\n",
    "    X,y = extractor.extract(hashtag)\n",
    "    X_decoded = extractor.decode()\n",
    "    \n",
    "    print(\"Retrieved \" + str(len(X_decoded)) + \" tweets about \" +  hashtag)\n",
    "    print(\"Check if y length matches: \" + str(len(y)))\n",
    "    \n",
    "    [newhashtags.extend(newhashtag) for newhashtag in y]\n",
    "    print(\"Current num of newhashtags: \" + str(len(newhashtags)))\n",
    "    \n",
    "    hashtag_X_doc = pipe.fit_transform(X_decoded)\n",
    "    \n",
    "    X_document.extend(hashtag_X_doc)\n",
    "    print(\"Current documents: \" + str(len(X_document)))\n",
    "    y_document.extend(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T10:42:40.035372Z",
     "start_time": "2020-06-11T10:42:38.664372Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"mined_data/X_document_200611.csv\",\"w+\") as X_document_csv:\n",
    "    csvWriter = csv.writer(X_document_csv,delimiter=',')\n",
    "    csvWriter.writerows(X_document)\n",
    "    \n",
    "with open(\"mined_data/y_document_200611.csv\",\"w+\") as y_document_csv:\n",
    "    csvWriter = csv.writer(y_document_csv,delimiter=',')\n",
    "    csvWriter.writerows(y_document)\n",
    "    \n",
    "with open(\"mined_data/newhashtags_200611.csv\",\"w+\") as newhashtags_csv:\n",
    "    csvWriter = csv.writer(newhashtags_csv,delimiter=',')\n",
    "    csvWriter.writerows(newhashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T13:33:39.105640Z",
     "start_time": "2020-06-10T13:33:39.095843Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import html\n",
    "\n",
    "class HashtagDetailsExtractor:\n",
    "    \n",
    "    def __init__(self,tweetnum=1000):\n",
    "        self.tweetnum = tweetnum\n",
    "        self.tweet_text_list = []\n",
    "        self.hashtaglists = []\n",
    "        \n",
    "    def decode(self):\n",
    "        decodedtweets = []\n",
    "        for tweet in self.tweet_text_list:\n",
    "            decodedtweets.append(html.unescape(tweet.decode(\"utf8\")))\n",
    "            \n",
    "        return decodedtweets\n",
    "        \n",
    "        \n",
    "    def extract(self,tag):\n",
    "        for tweet in tweepy.Cursor(api.search,q=tag,tweet_mode=\"extended\",full_text=True).items(self.tweetnum):\n",
    "            if(tweet.lang==\"en\"):\n",
    "#                 tweet_text_list.append(tweet._json[\"full_text\"].lower())\n",
    "                if('retweeted_status' in tweet._json):\n",
    "                    self.tweet_text_list.append(tweet._json['retweeted_status']['full_text'].encode(\"utf8\"))\n",
    "                else:\n",
    "                    self.tweet_text_list.append(tweet.full_text.encode(\"utf8\"))\n",
    "                hashtags = tweet._json[\"entities\"][\"hashtags\"]\n",
    "                hashtaglist = []\n",
    "                for i in range(len(hashtags)):\n",
    "                    hashtagstring = \"#\" + hashtags[i][\"text\"]\n",
    "                    hashtaglist.append(hashtagstring.lower())\n",
    "                \n",
    "                self.hashtaglists.append(hashtaglist)\n",
    "        \n",
    "        return self.tweet_text_list, self.hashtaglists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T13:34:25.601853Z",
     "start_time": "2020-06-10T13:33:43.101964Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extractor = HashtagDetailsExtractor()\n",
    "\n",
    "X,y = extractor.extract(\"#love\")\n",
    "\n",
    "X_decoded = extractor.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T21:39:09.863568Z",
     "start_time": "2020-06-10T21:39:09.858139Z"
    }
   },
   "outputs": [],
   "source": [
    "from  nltk.tokenize import TweetTokenizer\n",
    "\n",
    "class Tokenizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Returns tokenized text with the supplied Tokenizer \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,tokenizer_model,lowercase=True):\n",
    "        self.tokenizer_model = tokenizer_model\n",
    "        self.lowercase = lowercase\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        tokenized_tweets = []\n",
    "        \n",
    "        for tweet_text in X:\n",
    "            tweet_text_tokenized = self.tokenizer_model.tokenize(tweet_text)\n",
    "            tokenized_tweets.append(tweet_text_tokenized)\n",
    "            \n",
    "        return tokenized_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T13:34:32.661075Z",
     "start_time": "2020-06-10T13:34:32.585542Z"
    }
   },
   "outputs": [],
   "source": [
    "tweettokenizer = TweetTokenizer()\n",
    "\n",
    "tokenizer = Tokenizer(tweettokenizer)\n",
    "\n",
    "X_tokenized = tokenizer.fit_transform(X_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T21:39:10.143872Z",
     "start_time": "2020-06-10T21:39:10.117748Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "import copy\n",
    "import emoji\n",
    "from emoji import UNICODE_EMOJI\n",
    "import functools\n",
    "import operator\n",
    "import re\n",
    "import unicodedata as ud\n",
    "\n",
    "class ConvertEmojis(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, tokenizer_model):\n",
    "        self.tokenizer_model = tokenizer_model\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def hasemoji(self,s):\n",
    "        em_split_emoji = emoji.get_emoji_regexp().split(s)\n",
    "        em_split_whitespace = [substr.split() for substr in em_split_emoji]\n",
    "        em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
    "        emojiExists = False\n",
    "        for emojiTest in em_split:\n",
    "            if(emojiTest in UNICODE_EMOJI):\n",
    "                emojiExists = True\n",
    "    \n",
    "        return emojiExists\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        emoji_seperator = TweetTokenizer()\n",
    "        X_copy = copy.deepcopy(X)\n",
    "        for i,tweet in enumerate(X):\n",
    "            shiftindex = 0\n",
    "            for ii,word_token in enumerate(tweet):\n",
    "                if(self.hasemoji(word_token)):\n",
    "                    em_split_emoji = emoji.get_emoji_regexp().split(word_token)\n",
    "                    em_split_whitespace = [substr.split() for substr in em_split_emoji]\n",
    "                    em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
    "                    emoji_detail_tokenized = []\n",
    "                    words = \"\"\n",
    "                    for iii,each_emoji in enumerate(em_split):\n",
    "                        try:\n",
    "                            emoji_detail = ud.name(each_emoji)\n",
    "                            emoji_tokenized = self.tokenizer_model.tokenize(emoji_detail.lower())\n",
    "                            if(emoji_tokenized[-1]==\"selector-16\" and emoji[-2]==\"variation\"):\n",
    "                                emoji_tokenized.clear()\n",
    "                            emoji_detail_tokenized.extend(emoji_tokenized)\n",
    "                        except:\n",
    "                            emoji_detail_tokenized.extend([each_emoji])\n",
    "                            pass\n",
    "                    X_copy[i].pop(ii + shiftindex)\n",
    "                    X_copy[i] = X_copy[i][:ii + shiftindex] + emoji_detail_tokenized + X_copy[i][ii + shiftindex:]\n",
    "                    shiftindex += len(emoji_detail_tokenized) - 1\n",
    "        return X_copy\n",
    "    \n",
    "class RemovePunctuation(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,charsequence):\n",
    "        self.charsequence = set(charsequence)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        for i,tweet in enumerate(X):\n",
    "            \n",
    "            X_copy[i] = [text for text in tweet if not set([text]).issubset(self.charsequence)]\n",
    "            \n",
    "        return X_copy\n",
    "    \n",
    "class Standardize(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "#     def __init__(self,charsequence):\n",
    "#         self.charsequence = set(charsequence)\n",
    "        \n",
    "    def fit(self, X , y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        standardizedtweets = []\n",
    "        \n",
    "        for i,tweet in enumerate(X):\n",
    "            rl_tknzedtweets = []\n",
    "            \n",
    "            for ii,word in enumerate(tweet):\n",
    "\n",
    "                if(word[0] == \"#\" or word[0] == \"@\"):\n",
    "                    rl_tknzedtweets.append(word[1:].lower())\n",
    "                elif(word[:8] == \"https://\"):\n",
    "                    pass\n",
    "                else:\n",
    "                    rl_tknzedtweets.append(word.lower())\n",
    "                    \n",
    "            standardizedtweets.append(rl_tknzedtweets)\n",
    "        \n",
    "        return standardizedtweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T13:35:58.285956Z",
     "start_time": "2020-06-10T13:35:57.708071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['all', 'i', 'can', 'be', 'music', 'riff', 'guitarist', 'art', 'artist', 'love', 'poetry', 'musician', 'lyrics', 'lyricist', 'video', 'viralvideos', 'peace', 'viral', 'freemusic', '11'], ['behold', 'the', 'mimimi', 'love', 'package', 'orange', 'heart', 'a', 'special', 'limited', 'version', 'of', 'the', 'desperados3', \"collector's\", 'edition', 'that', 'is', 'exclusively', 'available', 'in', 'our', 'eshop', 'made', 'w', '/', 'mimimi', 'love', 'very', 'cool', 'the', 'limited', 'movie-style', 'desperados3', 'poster', 'signed', 'by', 'us', '!', 'pre-order', 'now'], ['follow', 'me', 'for', 'more', 'quotes', 'on', 'love', 'relationships', 'soulmates', 'womanhood', 'positivethoughts'], ['without', 'it', 'relationships', 'can', 'get', 'ugly', '...', 'via', 'youtube', 'men', 'women', 'love', 'relationships', 'dating', 'datingsteadygopodcast'], ['wonderful', 'evening', 'and', 'good', 'night', 'to', 'everyone', 'call', 'me', 'hand', 'surfer', 'emoji', 'modifier', 'fitzpatrick', 'type', '-1-2', '\\u200d', 'male', 'sign', '️', 'surfer', '\\u200d', 'female', 'sign', '️', 'sleeping', 'face', 'sunset', 'surf', 'saltlife', 'playa', 'ocean', 'vitaminsea', '\\u2060', '\\u2060', '\\u2060', '\\u2060', 'goodvibesonly', 'love', 'enjoytheview'], ['i', 'dreamt', 'an', 'angel', 'by', 'artist', 'palette', 'copyright', 'sign', '️bruce', 'neeley', '2020', 'writing', 'hand', 'emoji', 'modifier', 'fitzpatrick', 'type', '-1-2', 'copyright', 'sign', '️tereza', 'gillespie', '2020', 'art', 'poetry', 'love', 'peace', 'heavy', 'black', 'heart', '️', 'shamrock', '️', 'front-facing', 'baby', 'chick', 'heavy', 'black', 'heart', '️', 'peace', 'symbol', '️', 'heavy', 'black', 'heart', '️', 'hugging', 'face', 'sparkles', 'person', 'with', 'folded', 'hands', 'rose', 'permanent', 'paper', 'sign', 'staysafe', 'staywell', 'stayfree', 'blm', 'equality', 'loveiseverything', 'alwaysbekind', 'heavy', 'black', 'heart', '️', 'peace', 'symbol', '️', 'person', 'with', 'folded', 'hands', 'sparkles', 'earth', 'globe', 'americas', 'earth', 'globe', 'asia-australia', 'earth', 'globe', 'europe-africa', 'sparkles', 'person', 'with', 'folded', 'hands', 'peace', 'symbol', '️', 'heavy', 'black', 'heart', '️'], ['fragile', 'barry', 'poetry', 'poet', 'writer', 'art', 'poetrycommunity', 'poetrywriter', 'scarletmonahan', 'love', 'words', '5'], ['helping', 'singles', 'meet', 'the', 'old', 'fashioned', 'way', 'singles', 'wearthelotus', 'meet', 'love', 'findlove', 'datingtips', 'dating'], ['restless', 'freemusic', 'music', 'riff', 'guitarist', 'art', 'artist', 'love', 'poetry', 'musician', 'lyrics', 'lyricist', 'video', 'viral', '7'], ['wednesdaythoughts', 'love', 'yourself', 'and', 'give', 'love', 'it', 'will', 'always', 'come', 'back', 'to', 'you', '...']]\n"
     ]
    }
   ],
   "source": [
    "perm = np.random.RandomState(seed=13).permutation(10)*10+200\n",
    "\n",
    "emojiConv = ConvertEmojis(tweettokenizer)\n",
    "X_no_emoji = emojiConv.fit_transform(X_tokenized)\n",
    "\n",
    "\n",
    "charsequence = [\".\",\"#\",\":\",\"•\",\",\",\"@\",\"\\\"\",\";\",\"\\'\",\")\",\"(\",\"&\",\"``\",\"\\'\\'\"]\n",
    "removePunc = RemovePunctuation(charsequence)\n",
    "X_no_punc = removePunc.fit_transform(X_no_emoji)\n",
    "\n",
    "standardizetweets = Standardize()\n",
    "X_standardized = standardizetweets.fit_transform(X_no_punc)\n",
    "\n",
    "\n",
    "\n",
    "print([X_standardized[i] for i in perm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T10:33:50.328056Z",
     "start_time": "2020-06-11T10:32:37.766556Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "\n",
    "EMB_DIM = 300\n",
    "\n",
    "w2v = Word2Vec(X_document,size=EMB_DIM, window=5, min_count=5, negative=15, iter=10, workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T10:33:54.828507Z",
     "start_time": "2020-06-11T10:33:54.821713Z"
    }
   },
   "outputs": [],
   "source": [
    "word_vectors = w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T10:38:28.159598Z",
     "start_time": "2020-06-11T10:38:28.149078Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ruined', 0.33852487802505493),\n",
       " ('exclamation', 0.320356160402298),\n",
       " ('orange', 0.3035481572151184),\n",
       " ('african-american', 0.28424960374832153),\n",
       " ('green', 0.27866750955581665),\n",
       " ('empathy', 0.276780903339386),\n",
       " ('stem', 0.27466681599617004),\n",
       " ('growing', 0.271255224943161),\n",
       " ('ribbon', 0.26473551988601685),\n",
       " ('blue', 0.26090165972709656)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
